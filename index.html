<!DOCTYPE html>
<html lang="en">

<head>
        <!-- ... other head elements ... -->
    
        <style>
            /* ... other styles ... */
    
            .experience-section {
            display: flex;
            flex-wrap: wrap;
            gap: 20px; /* Adjust the gap between items */
            }
    
            .experience-entry {
            flex-basis: calc(33.333% - 20px); /* Adjust for three columns */
            min-width: 250px; /* Adjust minimum width as needed */
            max-width: 100%;
            }
            .education-section {
            display: flex;
            flex-wrap: wrap;
            gap: 30px; /* Adjust the gap between items */
            }
            .education-entry h3 {
            flex-basis: calc(50% - 30px); /* Adjust for three columns */
            min-width: 300px; /* Adjust minimum width as needed */
            max-width: 100%;
            }
        </style>
</head>
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Your Name - Portfolio</title>
    <style>
        body {
            font-family: Arial, sans-serif;
        }

        header {
            display: flex;
            align-items: center;
            padding: 20px;
            background-color: #f4f4f4;
        }

        .header-content {
            text-align: left;
            margin-left: 20px;
        }

        .header-img {
            width: 150px;
            height: 150px;
            border-radius: 50%; /* Circular image */
        }

        section {
            margin-left: 20px;
            padding: 10px;
        }

        footer {
            text-align: center;
            padding: 20px;
            background-color: #f4f4f4;
        }
    </style>
</head>
<body>

<header>
    <img src="headshot_2.jpg" alt="Your Name" class="header-img">
    <div class="header-content">
        <h1>Ahmed Hasssan</h1>
        <p>PhD Scholar | <a href="https://seo.ece.cornell.edu/" target="_blank">Seo Research Group</a> | Cornell University</p>
        <p>Email: <a href="ah2288@cornell.edu">ah2288@cornell.edu</a> | Phone: 602-727-7346 | <a href="https://www.linkedin.com/in/ahmed-hasssan-822a29a2/" target="_blank">LinkedIn Profile</a> </p>
    </div>
</header>

<section id="about">
    <h2 style="background: linear-gradient(to right, red, orange); color: white; padding: 10px;">About Me</h2>
    <p>I am a 5th year Ph.D. student at Cornell University (Tech), working as a Research Associate under the supervision of <a href="https://www.tech.cornell.edu/people/jae-sun-seo/" target="_blank">Professor Jae-sun Seo</a> in the Department of Electrical and Computer Engineering. My research is primarily at the intersection of software/hardware co-design for computer vision, 3D scene rendering and language models (SSM and Transformers) using the intricate processes of quantization, pruning, and neural architecture search for custom hardware and mobile devices.</p>
    <p>I have completed my Master's degree from Government College University, Lahore, and hold a Bachelor's degree from COMSATS University Islamabad, Pakistan.</p>
    <p>I am graduating around the summer of 2025 and actively looking for the full-time roles related to 2D/3D computer vision or large large langauge model fine-tuning and inference for custom on-device AI applications.</p>
    <!-- <a href="https://drive.google.com/file/d/1MtyCwUPkFzLyD1tTIw_v-XJPG_h-8wmD/view?usp=sharing" target="_blank">Resume</a> -->
</section>

<section id="education">
    <h2 class="styled-heading">Education</h2>
    <div class="education-section">
    <div class="education-entry">
        <h3>Ph.D. in Electrical and Computer Engineering<a href="https://drive.google.com/file/d/1wZvh-fKIjZtGLgtCfK6WjFPGLIMI9kiA/view?usp=sharing" target="_blank">(Transcript)</a></h3>
        <p>Cornell University (Tech), NY</p>
        <p>2023 - Present</p>
        <h4>Advisors: <a href="https://www.tech.cornell.edu/people/jae-sun-seo/" target="_blank">Professor Jae-sun Seo</a>
        , <a href="https://tech.cornell.edu/people/mohamed-abdelfattah/" target="_blank">Professor Mohamad Abdelfattah</a>
        </h4>
    </div>

    <div class="education-entry">
        <h3>Ph.D. in Electrical and Computer Engineering<a href="https://drive.google.com/file/d/13UUqgEf43XMpZbSbMhInhi35ne7_MZe2/view?usp=sharing" target="_blank">(Transcript)</a></h3>
        <p>Arizona State University, NY</p>
        <p>2020 - 2023</p>
        <h4>Advisors: <a href="https://www.tech.cornell.edu/people/jae-sun-seo/" target="_blank">Professor Jae-sun Seo</a>
        , <a href="https://search.asu.edu/profile/749044" target="_blank">Professor Yu(Kevin) Cao</a>
        , <a href="https://search.asu.edu/profile/3509434" target="_blank">Professor Deliang Fan</a>
        </h4>
    </div>

    <div class="education-entry">
        <h3>Master's Degree</h3>
        <p>Government College University, Lahore</p>
        <p>2017 - 2019</p>
    </div>

    <div class="education-entry">
        <h3>Bachelor's Degree</h3>
        <p>COMSATS University, Islamabad, Pakistan</p>
        <p>2011 - 2015</p>
    </div>
    </div>
</section>

<section id="experience">
    <h2>Research and Professional Experience</h2>
    <div class="experience-section">
    <div class="experience-entry">
        <h3>On-device AI Research Intern, AI Center</h3>
        <p>Samsung Research America, Mountain View, CA</p>
        <p>May 2024 – Aug 2024</p>
        <h4>Manager: <a href="https://www.linkedin.com/in/yenchanghsu/" target="_blank">Yen-Chang Hsu</a></h4>
    </div>
    <div class="experience-entry">
        <h3>Graduate Research Assistant</h3>
        <p>Cornell University (Tech), NY</p>
        <p>Aug 2023 – Present</p>
        <h4>Advisor: <a href="https://www.tech.cornell.edu/people/jae-sun-seo/" target="_blank">Professor Jae-sun Seo</a></h4>
    </div>
    <div class="experience-entry">
        <h3>Design Technology Enablement Intern</h3>
        <p>Intel Corporations, Hillsboro, OR</p>
        <p>May 2022 – March 2023</p>
        <h4>Manager: <a href="https://www.linkedin.com/in/muhammad-ali-0bb811/" target="_blank"> Muhammad Ali</a></h4>
    </div>
    <div class="experience-entry">
        <h3>Research Associate</h3>
        <p>Seo Lab, Arizona State University, AZ</p>
        <p>Aug 2021 – Aug 2023</p>
        <h4>Advisor: <a href="https://www.tech.cornell.edu/people/jae-sun-seo/" target="_blank">Professor Jae-sun Seo</a></h4>
    </div>
    <div class="experience-entry">
        <h3>Research Associate</h3>
        <p>Optoelectronics Lab, ASU, AZ</p>
        <p>Aug 2020 – July 2021</p>
        <h4>Advisor: <a href="https://search.asu.edu/profile/2465249" target="_blank">Dr. Yu Yao</a></h4>
    </div>
    <div class="experience-entry">
        <h3>Research Officer</h3>
        <p>Computer Vision Lab, KICS LHR,PK</p>
        <p>Mar 2020 – Oct 2020</p>
        <h4>Manager: <a href="https://www.kics.edu.pk/staff/usmanghani_khan" target="_blank">Muhammad Usman Ghani</a></h4>
    </div>
</div>
</section>

<section id="teaching-experience">
    <h2>Teaching Experience</h2>
    <h3>Lab Engineer</h3>
    <p>Sharif College of Engineering LHR,PK</p>
    <p>May 2015 – Feb 2020</p>
    <h4>Manager: <a href="https://scet.sharif.edu.pk/member/mazhar-iqbal/" target="_blank">Mazhar Iqbal</a></h4>
</section>

<section id="publications">
    <h2>Publications</h2>
        <h3>Submitted Papers</h3>
    
        <h3>Published Papers</h3>
    <ul>
        <li> Hasssan, A., Meng, J., Anupreethem, A. and Seo, J. "QUANT-NERF: Efficient End-to-end Quantization of Neural Radiance Fields with Low-Precision 3D Gaussian Representation”. ICASSP, 2025.</li>
        <li><a href="https://www.frontiersin.org/journals/neuroscience/articles/10.3389/fnins.2024.1440000/full" target="_blank">[URL]</a> Hasssan, A., Meng, J., Anupreethem, A. and Seo, J. "SpQuant-SNN: ultra-low precision membrane potential with sparse activations unlock the potential of on-device spiking neural networks applications", Frontier of Neuroscience, 2024.</li>
        <li><a href="https://proceedings.mlsys.org/paper_files/paper/2024/file/b8bf2c0dd0b48511889b7d3b2c5fc8f5-Paper-Conference.pdf" target="_blank">[URL]</a> Meng, J., Leo, Y., Anupreetham, A., Hasssan, A., et al “Torch2Chip: An End-to-end Customizable Deep Neural Network Compression and Deployment Toolkit for Prototype Hardware Accelerator Design", MLSys, 2024.</li>
        <li><a href="https://ieeexplore.ieee.org/abstract/document/10650320" target="_blank">[URL]</a> Hasssan, A., Meng, J., and Seo, J. "Spiking Neural Network with Learnable Threshold for Event-based Classification and Object Detection" IJCNN, 2024.</li>
        <li><a href="https://iconsneuromorphic.cc/schedule/" target="_blank">[URL]</a> Hasssan, A., Meng, J., Anupreethem, A. and Seo, J. "IM-SNN Memory-Efficient SNN with Low-Precision Membrane Potential and Weights" ACM ICONS, 2024.</li>
        <li><a href="https://ieeexplore.ieee.org/document/10347978" target="_blank">[URL]</a> Nair, G.R., Nalla, P.S., Krishnan, G., Anupreetham, A., Hasssan, A., Yeo, I., et al. “3D In-Sensor Computing for Real-time DVS Data Compression: 65nm Hardware-Algorithm Co-design", IEEE Solid-State Circuits Letters, 2024.</li>
        <li><a href="https://ieeexplore.ieee.org/document/10347978" target="_blank">[URL]</a> Krishnan, G., Nair, G.R., Oh, J., Anupreetham, A., Nalla, P.S., Hassan, A., Yeo, I., et al. "3D-ISC: A 65nm 3D Compatible In-Sensor Computing Accelerator with Reconfigurable Tile Architecture for Real-Time DVS Data Compression", IEEE Asian Solid-State Circuits Conference (A-SSCC), 2023.</li>
        <li><a href="https://www.researchgate.net/publication/377552110_Field_Deployable_Mirror_Soiling_Detection_Based_on_Polarimetric_Imaging" target="_blank">[URL]</a> Rafique, M. Z. E., Faruque, H. M. R., Hassan, A., Tian, M., Das, N., & Yao, Y. “Field Deployable Mirror Soiling Detection Based on Polarimetric Imaging”, SolarPACES Conference Proceedings, 2022.</li>
        <li><a href="https://ieeexplore.ieee.org/document/9864008" target="_blank">[URL]</a> Seo, J.S., Saikia, J., Meng, J., Hasssan, A., et al. "Digital versus analog artificial intelligence accelerators: Advances, trends, and emerging designs", IEEE Solid-State Circuits Magazine 14.3 (2022): 65-79.</li>
        <li><a href="https://ieeexplore.ieee.org/abstract/document/10051946" target="_blank">[URL]</a> Hasssan, A., Meng, J., Cao, Y., & Seo, J. S. “Spatial-temporal Data Compression of Dynamic Vision Sensor Output with High Pixel-level Saliency using Low-precision Sparse Autoencoder”, 56th Asilomar Conference on Signals, Systems, and Computers, 2022 (pp. 344-348).</li>
        <li> Meng*, J., Hasssan*, A., and Seo, J. “LT-SNN: Self-adaptive Spiking Neural Network with Learnable Threshold”, Techcon, Semiconductor Research Corporation, 2022.</li>
        <li><a href="https://www.semanticscholar.org/paper/Smart-Tunnel-Farming-Model%3A-An-Inculcation-of-Cloud-Alam-Hasssan/e00ffd047a2b956fa855738be92555706fc1addd" target="_blank">[URL]</a> Alam, S. M., Hasssan, A., et al. “Smart tunnel farming model: an inculcation of cloud computing with cortex for reliable agricultural production”, International Journal of Sensor Networks and Data Comm, 7(4), 1-11, 2018.</li>
        <li><a href="https://www.sciencedirect.com/science/article/pii/S1364032115015749?casa_token=3aiVKY3AEgsAAAAA:8EEMYh_5hYs5Ske85AUy4FGHv22s5QIOuHnFobe1TqFLt7rhIAE1nhILPrRMC850lb60eIInjg" target="_blank">[URL]</a>Ahmed, S., Mahmood, A., Hasan, A., et al. “A comparative review of China, India, and Pakistan renewable energy sectors and sharing opportunities”, Renewable and Sustainable Energy Reviews, 57, 216-225, 2016.</li>
        <li><a href="https://d1wqtxts1xzle7.cloudfront.net/54847512/141-libre.pdf?1509210574=&response-content-disposition=inline%3B+filename%3DPeak_Load_Shaving_Model_Based_on_Individ.pdf&Expires=1702712182&Signature=LL~raI8k6367lLLSnB3Zs67uRGBealVZ543-Mav6WdtyQ-~bteaJIX1SqQ2qJa~b~4fo3y9lHCXwW5EhcseWcU8jqGlMnjMFaxHQHoD24BBYSyuBtVSDDyLhNfY~UKgrqs1mopOLiF5iKfdWp~uVUWTeEPnO1oOAWMbif6KXw6LMiRh365CrTkCFa8u5Looszjh7TZtm1osBVU~1dbgn9tesgh4-rqJxLZq2BkZbkoHcO4gGb4PXHP1r2wJ4FzEDgLnWOGg43eWvtSev1mYAg8BdNTKqhIlfkn55hA0t0a5s3WibBC6CLnDI4ObXJ2Jka0XvED0AL4R2liSWYSw87w__&Key-Pair-Id=APKAJLOHF5GGSLRBV4ZA" target="_blank">[URL]</a>Ashraf, H., Hassan, A., Khurshid, U., Mahmood, A., Shaheen, N., Khan, Z. A., ... & Javaid, N. (2015, July). "Peak load shaving model based on individual's habit", Ninth International Conference on Complex, Intelligent, and Software Intensive Systems, 2015 (pp. 276-282). IEEE.</li>
    </ul>
</section>

<section id="achitvements and awards">
    <h2>Achitvements and Awards</h2>
    <ul>
        <li>Intel recognition award for best performance during the quarter [May 2022 - August 2022].</li>
        <li>Best teacher award at Sharif College of Engineering and Technology [Dec 2020].</li>
        <li>Poster compition winner, IEEE ComSoc Lahore [Nov 2018].</li>
    </ul>
</section>

<section id="projects">
    <h2>Research Projects on Large Language Models</h2>
    <div>
        <h3>Optimization of Prefill Time/ Time to First Token Generation of Mamba (SSM) for Faster On-device Inference</h3>
        <ul>
            <li>Developed on-device LLM latency profiler for Mobile devices using Llamacpp plateform.</li>
            <li>Performed LLM latency profiling on CPU, GPU, and Samsung S23 Mobile CPU using Llamacpp to identify latency hotspots of different operations.</li>
            <li>Compared the throughput and latency of Transformer and Mamba models on CPU, GPU, and Samsung S23 Mobile CPU.</li> 
            <li>Implemented divide and concur-based Parallel Scan on Pytorch and Llamacpp to reduce the on-device prefill/first token generation latency for Mamba-1.4 and Mamba-2.8 models with higher context length >5k.</li> 
            <li>Reduced the prompt eval (TTFT) latency by Log(N) and achieved 1.39X speedup for Mamba 1.1B on a Samsung S23 device using Llamacpp.</li>
            <li>Working on Multi-threaded parallel scan to support the 5 threads of Samsung S23 Mobile device.</li>
        </ul>
    </div>
    <h2>Research Projects on 3D Computer Vision</h2>
    <div>
        <h3>Low-precision and Memory Efficient Neural Radiance Fields (NeRF) with Hardware Accelerator Design</h3>
        <ul>
            <li>Developed efficient NeRF with low-precision 3D Gaussian-based conical frustums for high-quality 3D scene generation.</li>
            <li>Implemented fixed-grid-based quantization scheme for low-precision representation of 3D Gaussian (8-nit and 3-bit).</li> 
            <li>Designed and implemented statistically-aware boundary clipping and quantization for low-precision representation MLP activations (8-bit precison).</li> 
            <li>Implemented adaptively rounding quantization scheme for low-precison weights representation to make the complete NeRF flow in 8-bit precision.</li>
            <li>Replaced the compute inefficient high-precision positional encoding with the fixed-precision (8-bit and 9-bit) look-up tables of Mean and Covariance for software/hardware level efficiency.</li>
            <li>Designed hardware Accelerator using look-up table approach for NeRF based 3D scene rendering.</li>
            <li>Achieved high average PSNR 31.70 and reduced the rendering time to 102s for a complete scene at the hardware-level.</li>
        </ul>
    </div>
    <div class="video-container">
        <iframe src="https://drive.google.com/file/d/1DseiToabBhxYJhSpKDzq0CQyRUj3ashh/preview" width="280" height="240" allow="autoplay"></iframe>
    </div>
    <div>
        <h3>Salient-Gaussians: 3D Gaussian Splatting with Direction Cosine and Gaussian Intrinsics based pruning. (Current Research Project)</h3>
        <ul>
            <li>Implemented direction cosine for high quality 3D scene rendering.</li>
            <li>Implemented Gaussiang Intrinsics based pruning mask computation to reduce the active Gaussians for final rendering.</li> 
            <li>Reduced the number of Gaussian by 5X without loosing the rendering quality in comprison to original 3DGS works.</li> 
            <li>Reduced the memory utilization of overall rendering process by 1.7X.</li>
        </ul>
    </div>
    <div class="video-container">
        <iframe src="https://drive.google.com/file/d/1L1VqBhAnWWAQuaj8Z8RhMSfdS-XtF68k/preview" width="280" height="240" allow="autoplay"></iframe>
    </div>
    <div class="video-container">
        <iframe src="https://drive.google.com/file/d/1n3Ysm8JBQ0T5xmVk4v9_PHU5Est58F2r/preview" width="280" height="240" allow="autoplay"></iframe>
    </div>
    <h2>Research Projects on 2D Computer Vision</h2>
    <div>
        <h3>LT-SNN: Spiking Neural Network with Learnable Threshold for Event-based Classification and Object Detection <a href="https://github.com/Ahmedhasssan/LV-Surrogate-Gradient-TE-SNN-VGG" target="_blank">[Code]</a></h3>
        <ul>
            <li>Designed a shallow Yolo-SNN architectures for event-based classification object detection.</li>
            <li>Implemented layer-wise learnable threshold in SNN for optimal learning.</li> 
            <li>Implemented sigmoid gradient surrogation for backward pass in SNN.</li>
            <li>Implemented low-precision representation of weights and activations using 4-bit quantization of membrane potential.</li> 
            <li>Achieved state-of-the-art accuracy 80.7 on DVS-CIFAR10 and mean avergae precision value (mAP) 0.30 on Prophesee Gen1 dataset.</li> 
        </ul>
        <img src="LT-SNN-Result.png" alt="LT-SNN Inference Results" class="header-img" width="800">
    </div>
    <div>
        <h3>Quantization methods for different architectures including CNN, SNN and NeRF <a href="https://github.com/Ahmedhasssan/Quantization_for_all" target="_blank">[Code]</a></h3>
        <ul>
            <li>Designed weight and activation quantization approaches to support low-prcision representation of different architectures.</li>
            <li>Implemented SAWB, Adaptive Rounding and fixed-gird for weight quantization</li> 
            <li>Implemented  PACT, fixed grid based and STE for activations quantization.</li> 
            <li>This work supports different architectures including CNNs, SNNs and 3D scene rendering architectures.</li>
        </ul>
    </div>
    <div>
        <h3>Low-precision-custom-SNN-Yolov2 for Object detection using Prophesee Gen1 and Gen4 Datasets <a href="https://github.com/Ahmedhasssan/SNN-YoloV2-Object-Detection" target="_blank">[Code]</a></h3>
        <ul>
            <li>Designed a shallow Yolo-SNN architectures for event-based object detection.</li>
            <li>Prepared Prophesee Gen1 and Gen4 data for object detection.</li> 
            <li>Implemented low-precision representation of weights and activations using 4-bit and 2-bit quantization of membrane potential.</li> 
            <li>Achieved state-of-the-art mean avergae precision value (mAP) 0.30 for Prophesee Gen1 dataset.</li> 
            <li>Validated the shallow-Yolo-SNN on Prophesee Gen4 (most complex event data to date) and achieved 0.24 mAP.</li>
        </ul>
    </div>
    <div>
        <h3>SpQuant-SNN: ultra-low precision membrane potential with sparse activations unlock the potential of on-device spiking neural networks applications<a href="https://github.com/Ahmedhasssan/IM_SNN" target="_blank">[Code]</a></h3>
        <ul>
            <li>Designed a 3-bit precision integer-only quantization scheme for membrane potential for VGG-SNN and Yolo-SNN architectures.</li>
            <li>Designed the complete SNN quantization flow to compress the models.</li> 
            <li>Implemented Spatial-Channel pruning with fully quantized SNN to develop SpQuant-SNN for efficient edge computations.</li> 
            <li>Benchmarked SpQuant-SNN on complex datasets with >3X memory and >5X FLOPs reduction within less than 1% accuracy drop.</li>
            <li>This work is accepted in Frontier of Neuroscience, 2024. The code will be available soon.</li>
        </ul>
    </div>
    <div>
        <h3>Self-supervised Learning with Vision Transformers for Downstream Tasks</h3>
        <ul>
            <li>Implemented mainstream vision transformer architectures for better feature learning on unlabeled data</li>
            <li>Simplified the pre-trained model to develop its tiny version for hardware-level translation.</li> 
            <li>Pre-trained the model on ImageNet-100 and ImageNet-1000 dataset and validated the slight imprivement in comparison to the currest SOTA works</li> 
            <li>This project is accepted in MLSys, 2024.</li>
        </ul>
    </div>
    <div>
        <h3>Low Precision CNN-based Architecture Design for Information Processing from Event-based Camera <a href="https://github.com/Ahmedhasssan/Spatial-temporal-DVS-data-compression-using-low-precision-autoencoder" target="_blank">[Code]</a></h3>
        <ul>
            <li>Designed low-precision sparse autoencoder architecture for Event (Prophesee-Gen1 and Prophesee-Gen4) data compression.</li>
            <li>Designed log of two-based quantization module to covert 32-bit weights and activations to 4-bit and 2-bit precision.</li> 
            <li>Achieved high accuracy >91% and mean average precision 0.30 with >10x image data compression for both Prophesee-Gen1 and Prophesee-Gen4 dataset.</li> 
            <li>Designed IMC-based hardware using proposed sparse and fully quantized autoencoder architecture for air traffic control applications.</li>
            <li>This project is accepted in Asilomar, 2022.</li>
        </ul>
    </div>
    <div>
        <h3>UNet based Image Segmentation Architecture Design and Convex hull implementation on segmented image for area extraction <a href="https://github.com/Ahmedhasssan/LP-Seg-UNET/tree/main" target="_blank">[Code]</a></h3>
        <ul>
            <li>Designed shallow UNet Architecture with low-precision weights and activations for image segmentation.</li>
            <li>Extracted convex hull to compute the object polygon area.</li> 
            <li>Achieved 0.99 IOU for the custom object dataset.</li>
        </ul>
    </div>
    <h2>Industry Projects</h2>
    <div>
        <h3>Optimization of Prefill Time/ Time to First Token Generation of Mamba (SSM) for Faster On-device Inference</h3>
        <ul>
            <li> I have worked on this project during my internship at Samsung Research America, AI Center</li>
            <li> Extended work on this project is still in progress</li>
        </ul>
        <h3>Estimation of Local Layout Effect (LLEs) using Machine Readable Specs (MRS) for Design Technology Team, Intel Corporations</h3>
        <ul>
            <li>Using LLE rules from the QA team, designed machine-readable specs to estimate the LLEs’ presence in the layouts.</li> 
            <li>Translated MRS into Python utility and validated automated LLE estimation using different layouts.</li>
            <li>Provided prototype version of python-based utility to QA and TTR team for small and large-scale layout testing.</li>
            <li>Documented the whole project and handed it over to the DE and QA team.</li>
            <li>Algorithm implementation is not availble due to industry rights.</li>
        </ul>
    </div>
    <div>
        <h3>Python-Based Automated Layout Generation for Different Cell Types, Intel Corporations</h3>
        <ul>
            <li>Developed Python algorithm to generate automatic and DRC clean layouts.</li> 
            <li>Generated and delivered layouts using a designed algorithm for LLE test cases, standard cells, and memory cells.</li>
            <li>Documented the whole project and handed it over to the DE and QA team.</li>
            <li>Algorithm implementation is not availble due to industry rights.</li>
        </ul>
    </div>
    <div>
        <h3>Pre-production Automated Verification and Completion of Design Run-sets, Intel Corporations</h3>
        <ul>
            <li>Implemented an algorithm to identify the key requirements and discrepancies of run-sets for auto-correction.</li> 
            <li>Documented the whole project and handed it over to the DE team.</li>
            <li>Algorithm implementation is not availble due to industry rights.</li>
        </ul>
    </div>
    <div>
        <h3>Deep Leaning-based Face attendance system, Jetson Tx2 and PYNQ-Z1 (XILINX)</h3>
        <ul>
            <li>Designed object detecion algorithm using YoloV3 backbone. Optimized the saved model using TensorRT.</li> 
            <li>Performed inference with optimized design on Jetson Tx2.</li>
            <li>Algorithm implementation is not availble due to industry rights.</li>
        </ul>
    </div>
</section>
<section id="projects">
    <h2>Conferences Attended</h2>
    <div>
        <h3>Techon 2022</h3>
        <ul>
            <li>Presented our group research on learnable potential threshold based Spiking neural Netwoeks.</li> 
        </ul>
        <h3>CBRIC Annual Review 2022</h3>
        <ul>
            <li>Presented our group research on scalability of Spiking Neural Networks for computer vision applications.</li> 
        </ul>
        <h3>Asilomar 2022</h3>
        <ul>
            <li>Presented my research paper "Spatial-temporal Data Compression of Dynamic Vision Sensor Output with High Pixel-level Saliency using Low-precision Sparse Autoencoder".</li> 
        </ul>
        <h3>COCOSYS Annual Review 2023</h3>
        <ul>
            <li>Presented our group research on compression and pruning of Spiking Neural Networks for computer vision applications.</li> 
        </ul>
        <h3>NeurIPS 2023</h3>
        <ul>
            <li>Attended coference to represent my research group and participated in different workshops related to stable diffusion.</li> 
        </ul>
    </div>
</section>>    

<footer>
    <p>© [2023] Ahmed Hasssan. All rights reserved.</p>
</footer>

</body>
</html>